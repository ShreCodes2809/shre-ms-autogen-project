{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18dc9cb4",
   "metadata": {},
   "source": [
    "### AutoGen Core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b59b939",
   "metadata": {},
   "source": [
    "Autogen Core decouples an agent's logic from how messages are delivered.\n",
    "The framework provides a communication infrastructure, along with agent lifecycle, and the agents are responsible for their own work.\n",
    "\n",
    "The communication infrastructure is called a Runtime.\n",
    "\n",
    "There are 2 types: **Standalone** and **Distributed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd8eda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from autogen_core import AgentId, MessageContext, RoutedAgent, message_handler\n",
    "from autogen_core import SingleThreadedAgentRuntime\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f21ea4",
   "metadata": {},
   "source": [
    "### Defining the Message object\n",
    "\n",
    "Whatever structure we want for messages in our Agent framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221883a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message:\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b944a7e9",
   "metadata": {},
   "source": [
    "### Define the Agent\n",
    "\n",
    "A subclass of RoutedAgent.\n",
    "\n",
    "Every Agent has an Agent ID which has 2 components:\n",
    "- `agent.id.type` describes the kind of agent it is\n",
    "- `agent.id.key` gives it its unique identifier\n",
    "\n",
    "Any method with the `@message_handler` decorated will have the opportunity to receive messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff94bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAgent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"Simple\")\n",
    "\n",
    "    @message_handler\n",
    "    async def on_my_message(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        return Message(content=f\"This is {self.id.type}-{self.id.key}. You said '{message.content}' and I disagree.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a5af45",
   "metadata": {},
   "source": [
    "This agent is not responsible for running any LLMs on it's own (logic) but it is used more like management construct. It holds the ID and the key for communication to take place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06652cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='simple_agent')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime = SingleThreadedAgentRuntime()\n",
    "await SimpleAgent.register(runtime, \"simple_agent\", lambda: SimpleAgent())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3132f15c",
   "metadata": {},
   "source": [
    "In the above code, only the type of the agent is decided but no agents are being created in the process. It is simply registering the agent \"SimpleAgent\" with the given runtime that can be spawned. The function inside lambda can create new versions of itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1606469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a runtime and send a message\n",
    "runtime.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb83026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> This is simple_agent-default. You said 'Well hi there!' and I disagree.\n"
     ]
    }
   ],
   "source": [
    "agent_id = AgentId(\"simple_agent\", \"default\")\n",
    "response = await runtime.send_message(Message(\"Well hi there!\"), agent_id)\n",
    "print(\">>>\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50ef4667",
   "metadata": {},
   "outputs": [],
   "source": [
    "await runtime.stop()\n",
    "await runtime.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf4aac",
   "metadata": {},
   "source": [
    "### Using an AgentChat Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86bb0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLMAgent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"LLMAgent\")\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(\"LLMAgent\", model_client=model_client)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        print(f\"{self.id.type} received message: {message.content}\")\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        reply = response.chat_message.content\n",
    "        print(f\"{self.id.type} responded: {reply}\")\n",
    "        return Message(content=reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "583820a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='LLMAgent')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_core import SingleThreadedAgentRuntime\n",
    "\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "await SimpleAgent.register(runtime, \"simple_agent\", lambda: SimpleAgent())\n",
    "await MyLLMAgent.register(runtime, \"LLMAgent\", lambda: MyLLMAgent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c142875b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMAgent received message: Hi there!\n",
      "LLMAgent responded: Hello! How can I assist you today?\n",
      ">>> Hello! How can I assist you today?\n",
      ">>> This is simple_agent-default. You said 'Hello! How can I assist you today?' and I disagree.\n",
      "LLMAgent received message: This is simple_agent-default. You said 'Hello! How can I assist you today?' and I disagree.\n",
      "LLMAgent responded: I apologize for any misunderstanding. How would you prefer I assist you today?\n"
     ]
    }
   ],
   "source": [
    "runtime.start()  # Start processing messages in the background.\n",
    "response = await runtime.send_message(Message(\"Hi there!\"), AgentId(\"LLMAgent\", \"default\"))\n",
    "print(\">>>\", response.content)\n",
    "response =  await runtime.send_message(Message(response.content), AgentId(\"simple_agent\", \"default\"))\n",
    "print(\">>>\", response.content)\n",
    "response = await runtime.send_message(Message(response.content), AgentId(\"LLMAgent\", \"default\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a66a790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "await runtime.stop()\n",
    "await runtime.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24e4e3c",
   "metadata": {},
   "source": [
    "### Agents interacting with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5cad1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "\n",
    "\n",
    "class Player1Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", temperature=1.0)\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "    \n",
    "class Player2Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", temperature=1.0)\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1b014c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "JUDGE = \"You are judging a game of rock, paper, scissors. The players have made these choices:\\n\"\n",
    "\n",
    "class RockPaperScissorsAgent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", temperature=1.0)\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        instruction = \"You are playing rock, paper, scissors. Respond only with the one word, one of the following: rock, paper, or scissors.\"\n",
    "        message = Message(content=instruction)\n",
    "        inner_1 = AgentId(\"player1\", \"default\")\n",
    "        inner_2 = AgentId(\"player2\", \"default\")\n",
    "        response1 = await self.send_message(message, inner_1)\n",
    "        response2 = await self.send_message(message, inner_2)\n",
    "        result = f\"Player 1: {response1.content}\\nPlayer 2: {response2.content}\\n\"\n",
    "        judgement = f\"{JUDGE}{result}Who wins?\"\n",
    "        message = TextMessage(content=judgement, source=\"user\")\n",
    "        response = await self._delegate.on_messages([message], ctx.cancellation_token)\n",
    "        return Message(content=result + response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "152f3cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = SingleThreadedAgentRuntime()\n",
    "await Player1Agent.register(runtime, \"player1\", lambda: Player1Agent(\"player1\"))\n",
    "await Player2Agent.register(runtime, \"player2\", lambda: Player2Agent(\"player2\"))\n",
    "await RockPaperScissorsAgent.register(runtime, \"rock_paper_scissors\", lambda: RockPaperScissorsAgent(\"rock_paper_scissors\"))\n",
    "runtime.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d467979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1: rock\n",
      "Player 2: rock\n",
      "In a game of rock, paper, scissors, if both players choose rock, it results in a tie. Therefore, no one wins in this round. \n",
      "\n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "agent_id = AgentId(\"rock_paper_scissors\", \"default\")\n",
    "message = Message(content=\"go\")\n",
    "response = await runtime.send_message(message, agent_id)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6eb4892",
   "metadata": {},
   "outputs": [],
   "source": [
    "await runtime.stop()\n",
    "await runtime.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
